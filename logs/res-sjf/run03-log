23/06/17 11:21:18 INFO client.RMProxy: Connecting to ResourceManager at /127.0.0.1:8032
23/06/17 11:21:19 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
23/06/17 11:21:20 INFO input.FileInputFormat: Total input paths to process : 16
23/06/17 11:21:21 INFO mapreduce.JobSubmitter: number of splits:16
23/06/17 11:21:22 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1687012831738_0003
23/06/17 11:21:23 INFO impl.YarnClientImpl: Submitted application application_1687012831738_0003
23/06/17 11:21:23 INFO mapreduce.Job: The url to track the job: http://pcvm716-2.emulab.net:8088/proxy/application_1687012831738_0003/
23/06/17 11:21:23 INFO mapreduce.Job: Running job: job_1687012831738_0003
23/06/17 11:21:43 INFO mapreduce.Job: Job job_1687012831738_0003 running in uber mode : false
23/06/17 11:21:43 INFO mapreduce.Job:  map 0% reduce 0%
23/06/17 11:24:03 INFO mapreduce.Job:  map 6% reduce 0%
23/06/17 11:24:08 INFO mapreduce.Job:  map 10% reduce 0%
23/06/17 11:24:09 INFO mapreduce.Job:  map 13% reduce 0%
23/06/17 11:24:33 INFO mapreduce.Job:  map 19% reduce 0%
23/06/17 11:24:38 INFO mapreduce.Job: Task Id : attempt_1687012831738_0003_m_000004_0, Status : FAILED
Container [pid=31578,containerID=container_1687012831738_0003_01_000006] is running beyond virtual memory limits. Current usage: 84.1 MB of 1 GB physical memory used; 3.4 GB of 2.1 GB virtual memory used. Killing container.
Dump of the process-tree for container_1687012831738_0003_01_000006 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 31619 31578 31578 31578 (java) 225 47 1832800256 10530 /usr/lib/jvm/java-8-openjdk-amd64/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx200m -Djava.io.tmpdir=/tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1687012831738_0003/container_1687012831738_0003_01_000006/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/usr/local/hadoop-2.7.6/logs/userlogs/application_1687012831738_0003/container_1687012831738_0003_01_000006 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog org.apache.hadoop.mapred.YarnChild 172.20.116.4 40671 attempt_1687012831738_0003_m_000004_0 6 
	|- 31711 31619 31578 31578 (java) 0 0 1832800256 10530 N/A
	|- 31578 31570 31578 31578 (bash) 1 2 13197312 466 /bin/bash -c /usr/lib/jvm/java-8-openjdk-amd64/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx200m -Djava.io.tmpdir=/tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1687012831738_0003/container_1687012831738_0003_01_000006/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/usr/local/hadoop-2.7.6/logs/userlogs/application_1687012831738_0003/container_1687012831738_0003_01_000006 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog org.apache.hadoop.mapred.YarnChild 172.20.116.4 40671 attempt_1687012831738_0003_m_000004_0 6 1>/usr/local/hadoop-2.7.6/logs/userlogs/application_1687012831738_0003/container_1687012831738_0003_01_000006/stdout 2>/usr/local/hadoop-2.7.6/logs/userlogs/application_1687012831738_0003/container_1687012831738_0003_01_000006/stderr  

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

23/06/17 11:24:42 INFO mapreduce.Job:  map 13% reduce 0%
23/06/17 11:25:14 INFO mapreduce.Job:  map 19% reduce 0%
23/06/17 11:25:19 INFO mapreduce.Job:  map 23% reduce 0%
23/06/17 11:25:24 INFO mapreduce.Job:  map 31% reduce 0%
23/06/17 11:29:22 INFO mapreduce.Job:  map 38% reduce 0%
23/06/17 11:29:47 INFO mapreduce.Job:  map 44% reduce 0%
23/06/17 11:29:57 INFO mapreduce.Job:  map 44% reduce 2%
23/06/17 11:30:25 INFO mapreduce.Job:  map 44% reduce 6%
23/06/17 11:30:33 INFO mapreduce.Job:  map 38% reduce 6%
23/06/17 11:30:36 INFO mapreduce.Job: Task Id : attempt_1687012831738_0003_m_000011_0, Status : FAILED
Container [pid=31555,containerID=container_1687012831738_0003_01_000013] is running beyond virtual memory limits. Current usage: 88.5 MB of 1 GB physical memory used; 3.4 GB of 2.1 GB virtual memory used. Killing container.
Dump of the process-tree for container_1687012831738_0003_01_000013 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 31555 31554 31555 31555 (bash) 0 4 13197312 464 /bin/bash -c /usr/lib/jvm/java-8-openjdk-amd64/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN  -Xmx200m -Djava.io.tmpdir=/tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1687012831738_0003/container_1687012831738_0003_01_000013/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/usr/local/hadoop-2.7.6/logs/userlogs/application_1687012831738_0003/container_1687012831738_0003_01_000013 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog org.apache.hadoop.mapred.YarnChild 172.20.116.4 40671 attempt_1687012831738_0003_m_000011_0 13 1>/usr/local/hadoop-2.7.6/logs/userlogs/application_1687012831738_0003/container_1687012831738_0003_01_000013/stdout 2>/usr/local/hadoop-2.7.6/logs/userlogs/application_1687012831738_0003/container_1687012831738_0003_01_000013/stderr  
	|- 31675 31559 31555 31555 (java) 0 1 1832800256 11101 N/A
	|- 31559 31555 31555 31555 (java) 303 78 1832800256 11101 /usr/lib/jvm/java-8-openjdk-amd64/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx200m -Djava.io.tmpdir=/tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1687012831738_0003/container_1687012831738_0003_01_000013/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/usr/local/hadoop-2.7.6/logs/userlogs/application_1687012831738_0003/container_1687012831738_0003_01_000013 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog org.apache.hadoop.mapred.YarnChild 172.20.116.4 40671 attempt_1687012831738_0003_m_000011_0 13 

Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

23/06/17 11:31:56 INFO mapreduce.Job:  map 69% reduce 6%
23/06/17 11:31:58 INFO mapreduce.Job:  map 88% reduce 6%
23/06/17 11:32:21 INFO mapreduce.Job:  map 88% reduce 8%
23/06/17 11:32:23 INFO mapreduce.Job:  map 75% reduce 8%
23/06/17 11:32:24 INFO mapreduce.Job: Task Id : attempt_1687012831738_0003_m_000012_0, Status : FAILED
AttemptID:attempt_1687012831738_0003_m_000012_0 Timed out after 600 secs
23/06/17 11:32:24 INFO mapreduce.Job: Task Id : attempt_1687012831738_0003_m_000013_0, Status : FAILED
AttemptID:attempt_1687012831738_0003_m_000013_0 Timed out after 600 secs
23/06/17 11:32:51 INFO mapreduce.Job:  map 75% reduce 10%
23/06/17 11:35:11 INFO mapreduce.Job:  map 81% reduce 10%
23/06/17 11:35:54 INFO mapreduce.Job:  map 100% reduce 10%
23/06/17 11:37:48 INFO mapreduce.Job:  map 94% reduce 10%
23/06/17 11:37:48 INFO mapreduce.Job: Task Id : attempt_1687012831738_0003_m_000007_0, Status : FAILED
AttemptID:attempt_1687012831738_0003_m_000007_0 Timed out after 600 secs
23/06/17 11:37:50 INFO mapreduce.Job: Task Id : attempt_1687012831738_0003_m_000005_0, Status : FAILED
AttemptID:attempt_1687012831738_0003_m_000005_0 Timed out after 600 secs
Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

23/06/17 11:37:51 INFO mapreduce.Job: Task Id : attempt_1687012831738_0003_m_000000_0, Status : FAILED
AttemptID:attempt_1687012831738_0003_m_000000_0 Timed out after 600 secs
23/06/17 11:37:51 INFO mapreduce.Job: Task Id : attempt_1687012831738_0003_m_000001_0, Status : FAILED
AttemptID:attempt_1687012831738_0003_m_000001_0 Timed out after 600 secs
Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

23/06/17 11:37:51 INFO mapreduce.Job: Task Id : attempt_1687012831738_0003_m_000002_0, Status : FAILED
AttemptID:attempt_1687012831738_0003_m_000002_0 Timed out after 600 secs
Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

23/06/17 11:38:11 INFO mapreduce.Job: Task Id : attempt_1687012831738_0003_m_000003_0, Status : FAILED
AttemptID:attempt_1687012831738_0003_m_000003_0 Timed out after 600 secs
Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

23/06/17 11:38:38 INFO mapreduce.Job:  map 94% reduce 13%
23/06/17 11:39:09 INFO mapreduce.Job: Task Id : attempt_1687012831738_0003_m_000012_1, Status : FAILED
AttemptID:attempt_1687012831738_0003_m_000012_1 Timed out after 600 secs
cleanup failed for container container_1687012831738_0003_01_000023 : java.io.IOException: Failed on local exception: java.io.IOException: java.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.20.116.4:58692 remote=pcvm716-3.emulab.net/172.20.116.3:35371]; Host Details : local host is: "slave1.hadoop-sjf.mapreduce630.emulab.net/172.20.116.4"; destination host is: "pcvm716-3.emulab.net":35371; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:776)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1413)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy81.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.stopContainers(ContainerManagementProtocolPBClientImpl.java:110)
	at sun.reflect.GeneratedMethodAccessor22.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy82.stopContainers(Unknown Source)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$Container.kill(ContainerLauncherImpl.java:207)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:379)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: java.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.20.116.4:58692 remote=pcvm716-3.emulab.net/172.20.116.3:35371]
	at org.apache.hadoop.ipc.Client$Connection$1.run(Client.java:688)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1758)
	at org.apache.hadoop.ipc.Client$Connection.handleSaslConnectionFailure(Client.java:651)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:738)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:376)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1452)
	... 15 more
Caused by: java.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.20.116.4:58692 remote=pcvm716-3.emulab.net/172.20.116.3:35371]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:367)
	at org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:561)
	at org.apache.hadoop.ipc.Client$Connection.access$1900(Client.java:376)
	at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:730)
	at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:726)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1758)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:726)
	... 18 more

23/06/17 11:39:10 INFO mapreduce.Job: Task Id : attempt_1687012831738_0003_m_000004_1, Status : FAILED
AttemptID:attempt_1687012831738_0003_m_000004_1 Timed out after 600 secs
cleanup failed for container container_1687012831738_0003_01_000019 : java.net.SocketTimeoutException: Call From slave1.hadoop-sjf.mapreduce630.emulab.net/172.20.116.4 to pcvm716-3.emulab.net:35371 failed on socket timeout exception: java.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.20.116.4:58680 remote=pcvm716-3.emulab.net/172.20.116.3:35371]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1413)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy81.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.stopContainers(ContainerManagementProtocolPBClientImpl.java:110)
	at sun.reflect.GeneratedMethodAccessor22.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy82.stopContainers(Unknown Source)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$Container.kill(ContainerLauncherImpl.java:207)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:379)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.20.116.4:58680 remote=pcvm716-3.emulab.net/172.20.116.3:35371]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:521)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1085)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:980)

23/06/17 11:39:10 INFO mapreduce.Job: Task Id : attempt_1687012831738_0003_m_000011_1, Status : FAILED
AttemptID:attempt_1687012831738_0003_m_000011_1 Timed out after 600 secs
cleanup failed for container container_1687012831738_0003_01_000022 : java.io.IOException: Failed on local exception: java.io.IOException: java.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.20.116.4:58688 remote=pcvm716-3.emulab.net/172.20.116.3:35371]; Host Details : local host is: "slave1.hadoop-sjf.mapreduce630.emulab.net/172.20.116.4"; destination host is: "pcvm716-3.emulab.net":35371; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:776)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1413)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy81.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.stopContainers(ContainerManagementProtocolPBClientImpl.java:110)
	at sun.reflect.GeneratedMethodAccessor22.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy82.stopContainers(Unknown Source)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$Container.kill(ContainerLauncherImpl.java:207)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:379)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: java.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.20.116.4:58688 remote=pcvm716-3.emulab.net/172.20.116.3:35371]
	at org.apache.hadoop.ipc.Client$Connection$1.run(Client.java:688)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1758)
	at org.apache.hadoop.ipc.Client$Connection.handleSaslConnectionFailure(Client.java:651)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:738)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:376)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1452)
	... 15 more
Caused by: java.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.20.116.4:58688 remote=pcvm716-3.emulab.net/172.20.116.3:35371]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:367)
	at org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:561)
	at org.apache.hadoop.ipc.Client$Connection.access$1900(Client.java:376)
	at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:730)
	at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:726)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1758)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:726)
	... 18 more

23/06/17 11:39:32 INFO mapreduce.Job: Task Id : attempt_1687012831738_0003_m_000005_1, Status : FAILED
AttemptID:attempt_1687012831738_0003_m_000005_1 Timed out after 600 secs
cleanup failed for container container_1687012831738_0003_01_000028 : java.io.IOException: Failed on local exception: java.io.IOException: java.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.20.116.4:58740 remote=pcvm716-3.emulab.net/172.20.116.3:35371]; Host Details : local host is: "slave1.hadoop-sjf.mapreduce630.emulab.net/172.20.116.4"; destination host is: "pcvm716-3.emulab.net":35371; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:776)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1413)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy81.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.stopContainers(ContainerManagementProtocolPBClientImpl.java:110)
	at sun.reflect.GeneratedMethodAccessor22.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy82.stopContainers(Unknown Source)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$Container.kill(ContainerLauncherImpl.java:207)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:379)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: java.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.20.116.4:58740 remote=pcvm716-3.emulab.net/172.20.116.3:35371]
	at org.apache.hadoop.ipc.Client$Connection$1.run(Client.java:688)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1758)
	at org.apache.hadoop.ipc.Client$Connection.handleSaslConnectionFailure(Client.java:651)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:738)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:376)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1452)
	... 15 more
Caused by: java.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.20.116.4:58740 remote=pcvm716-3.emulab.net/172.20.116.3:35371]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:367)
	at org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:561)
	at org.apache.hadoop.ipc.Client$Connection.access$1900(Client.java:376)
	at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:730)
	at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:726)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1758)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:726)
	... 18 more

23/06/17 11:39:33 INFO mapreduce.Job: Task Id : attempt_1687012831738_0003_m_000013_1, Status : FAILED
AttemptID:attempt_1687012831738_0003_m_000013_1 Timed out after 600 secs
cleanup failed for container container_1687012831738_0003_01_000024 : java.io.IOException: Failed on local exception: java.io.IOException: java.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.20.116.4:58690 remote=pcvm716-3.emulab.net/172.20.116.3:35371]; Host Details : local host is: "slave1.hadoop-sjf.mapreduce630.emulab.net/172.20.116.4"; destination host is: "pcvm716-3.emulab.net":35371; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:776)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1413)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy81.stopContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.stopContainers(ContainerManagementProtocolPBClientImpl.java:110)
	at sun.reflect.GeneratedMethodAccessor22.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy82.stopContainers(Unknown Source)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$Container.kill(ContainerLauncherImpl.java:207)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:379)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: java.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.20.116.4:58690 remote=pcvm716-3.emulab.net/172.20.116.3:35371]
	at org.apache.hadoop.ipc.Client$Connection$1.run(Client.java:688)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1758)
	at org.apache.hadoop.ipc.Client$Connection.handleSaslConnectionFailure(Client.java:651)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:738)
	at org.apache.hadoop.ipc.Client$Connection.access$2900(Client.java:376)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1529)
	at org.apache.hadoop.ipc.Client.call(Client.java:1452)
	... 15 more
Caused by: java.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.20.116.4:58690 remote=pcvm716-3.emulab.net/172.20.116.3:35371]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:367)
	at org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:561)
	at org.apache.hadoop.ipc.Client$Connection.access$1900(Client.java:376)
	at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:730)
	at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:726)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1758)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:726)
	... 18 more

23/06/17 11:39:36 INFO mapreduce.Job:  map 63% reduce 13%
23/06/17 11:39:37 INFO mapreduce.Job:  map 67% reduce 13%
23/06/17 11:39:43 INFO mapreduce.Job:  map 69% reduce 15%
23/06/17 11:39:56 INFO mapreduce.Job:  map 69% reduce 17%
23/06/17 11:40:05 INFO mapreduce.Job:  map 73% reduce 17%
23/06/17 11:40:06 INFO mapreduce.Job:  map 79% reduce 17%
23/06/17 11:40:11 INFO mapreduce.Job:  map 81% reduce 17%
23/06/17 11:40:19 INFO mapreduce.Job:  map 81% reduce 21%
23/06/17 11:42:42 INFO mapreduce.Job:  map 94% reduce 21%
23/06/17 11:42:56 INFO mapreduce.Job:  map 100% reduce 21%
23/06/17 11:43:17 INFO mapreduce.Job:  map 100% reduce 27%
23/06/17 11:43:21 INFO mapreduce.Job:  map 100% reduce 31%
23/06/17 11:43:58 INFO mapreduce.Job:  map 100% reduce 33%
23/06/17 11:44:01 INFO mapreduce.Job:  map 100% reduce 67%
23/06/17 11:44:05 INFO mapreduce.Job:  map 100% reduce 100%
23/06/17 11:44:17 INFO mapreduce.Job: Job job_1687012831738_0003 completed successfully
23/06/17 11:44:18 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
23/06/17 11:44:18 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
23/06/17 11:44:18 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
Exception in thread "main" java.io.IOException: java.io.IOException: Unknown Job job_1687012831738_0003
	at org.apache.hadoop.mapreduce.v2.hs.HistoryClientService$HSClientProtocolHandler.verifyAndGetJob(HistoryClientService.java:218)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryClientService$HSClientProtocolHandler.getCounters(HistoryClientService.java:232)
	at org.apache.hadoop.mapreduce.v2.api.impl.pb.service.MRClientProtocolPBServiceImpl.getCounters(MRClientProtocolPBServiceImpl.java:159)
	at org.apache.hadoop.yarn.proto.MRClientProtocol$MRClientProtocolService$2.callBlockingMethod(MRClientProtocol.java:281)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1758)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hadoop.mapred.ClientServiceDelegate.invoke(ClientServiceDelegate.java:344)
	at org.apache.hadoop.mapred.ClientServiceDelegate.getJobCounters(ClientServiceDelegate.java:382)
	at org.apache.hadoop.mapred.YARNRunner.getJobCounters(YARNRunner.java:590)
	at org.apache.hadoop.mapreduce.Job$7.run(Job.java:761)
	at org.apache.hadoop.mapreduce.Job$7.run(Job.java:758)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1758)
	at org.apache.hadoop.mapreduce.Job.getCounters(Job.java:758)
	at org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1383)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1311)
	at wordcount.WordCount.main(WordCount.java:60)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
Caused by: java.io.IOException: Unknown Job job_1687012831738_0003
	at org.apache.hadoop.mapreduce.v2.hs.HistoryClientService$HSClientProtocolHandler.verifyAndGetJob(HistoryClientService.java:218)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryClientService$HSClientProtocolHandler.getCounters(HistoryClientService.java:232)
	at org.apache.hadoop.mapreduce.v2.api.impl.pb.service.MRClientProtocolPBServiceImpl.getCounters(MRClientProtocolPBServiceImpl.java:159)
	at org.apache.hadoop.yarn.proto.MRClientProtocol$MRClientProtocolService$2.callBlockingMethod(MRClientProtocol.java:281)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1758)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:95)
	at org.apache.hadoop.mapreduce.v2.api.impl.pb.client.MRClientProtocolPBClientImpl.unwrapAndThrowException(MRClientProtocolPBClientImpl.java:291)
	at org.apache.hadoop.mapreduce.v2.api.impl.pb.client.MRClientProtocolPBClientImpl.getCounters(MRClientProtocolPBClientImpl.java:168)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.mapred.ClientServiceDelegate.invoke(ClientServiceDelegate.java:325)
	... 17 more
Caused by: org.apache.hadoop.ipc.RemoteException(java.io.IOException): Unknown Job job_1687012831738_0003
	at org.apache.hadoop.mapreduce.v2.hs.HistoryClientService$HSClientProtocolHandler.verifyAndGetJob(HistoryClientService.java:218)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryClientService$HSClientProtocolHandler.getCounters(HistoryClientService.java:232)
	at org.apache.hadoop.mapreduce.v2.api.impl.pb.service.MRClientProtocolPBServiceImpl.getCounters(MRClientProtocolPBServiceImpl.java:159)
	at org.apache.hadoop.yarn.proto.MRClientProtocol$MRClientProtocolService$2.callBlockingMethod(MRClientProtocol.java:281)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:616)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2217)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2213)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1758)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2213)

	at org.apache.hadoop.ipc.Client.call(Client.java:1476)
	at org.apache.hadoop.ipc.Client.call(Client.java:1413)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy15.getCounters(Unknown Source)
	at org.apache.hadoop.mapreduce.v2.api.impl.pb.client.MRClientProtocolPBClientImpl.getCounters(MRClientProtocolPBClientImpl.java:166)
	... 22 more
